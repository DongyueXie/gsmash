---
title: "normal mean penalized optimization, estimate prior mean"
author: "Dongyue Xie"
date: "2022-10-10"
output: workflowr::wflow_html
editor_options:
  chunk_output_type: console
---

## Introduction

Add support for prior mean, $g=\sum_k\pi_k N(\mu,\sigma^2_k)$.

See the [previous one](normal_mean_penalized_optimization.html) for the case with $\mu=0$.

```{r}
source("code/normal_mean_model_utils.R")
```

```{r}
set.seed(12345)
n = 300
w0 = 0.9
lambda = c(rep(0,round(n*w0)),rep(10,n-round(n*w0)))
w_true = c(w0,1-w0)
grid_true = c(0.01,7)
s = rep(1,n)
y = rnorm(n,lambda,s)
library(ashr)
fit.ash = ashr::ash(y,s,mixcompdist = 'normal',mode='estimate')
#grid = exp(seq(log(s/100),log(sqrt(max(abs(y^2-s^2)))),by=log(sqrt(2))))
#fit.ash = S(y,s,w_true,grid_true)
#plot(fit.ash$fitted_g$sd,fit.ash$fitted_g$pi)
grid = fit.ash$fitted_g$sd
K = length(grid)
```

```{r}
ploter = function(fit,y,lambda,main='known prior'){
  plot(y,main=main,col='grey80')
  lines(lambda,col='grey60')
  lines(fit$z,type='p',pch=20,col='grey80')
  lines(fit$posteriorMean)
  legend('topleft',c('data','z','true mean','estimated mean'),pch=c(1,20,NA,NA),lty=c(NA,NA,1,1),col=c('grey80','grey80','grey60',1))
}
```

## ash fit

```{r,warning=FALSE}
fit.ash = ash(y,s,mixcompdist = 'normal',pointmass=F,prior='uniform',mixsd=grid,mode='estimate')
plot(y,main='ash fit',col='grey80')
lines(lambda,col='grey60')
lines(fit.ash$result$PosteriorMean)
legend('topleft',c('data','true mean','ash posteriorMean'),pch=c(1,NA,NA),lty=c(NA,1,1),col=c('grey80','grey60',1))
fit.ash$fitted_g
```

## Compound method

```{r}
#'objective function
#'@param theta (z,w,mu)
#'@param grid prior sds
f_obj = function(theta,y,s,grid){
  n = length(y)
  K = length(grid)
  w = softmax(theta[(n+1):(n+K)])
  z = theta[1:n]
  mu = theta[n+K+1]
  
  res = sum((y-z-s^2*l_nm_d1_z(z,s,w,mu,grid))^2/2/s^2 - l_nm(z,s,w,mu,grid) - s^2*(l_nm_d1_z(z,s,w,mu,grid))^2/2)

  return(res)
}

#'objective function
#'@param theta (mu_bar,w,mu)
#'@param grid prior sds
f_obj_grad = function(theta,y,s,grid){
  n = length(y)
  K = length(grid)
  a = theta[(n+1):(n+K)]
  w = softmax(a)
  z = theta[1:n]
  mu = theta[n+K+1]
  
  grad_z = (1+s^2*l_nm_d2_z(z,s,w,mu,grid))*(z-y)/s^2
  grad_a = colSums((s^2*l_nm_d1_z(z,s,w,mu,grid)-y+z)*l_nm_d2_za(z,s,a,mu,grid) - l_nm_d1_a(z,s,a,mu,grid) - s^2*l_nm_d1_z(z,s,w,mu,grid)*l_nm_d2_za(z,s,a,mu,grid))
  grad_mu = sum(-(l_nm_d2_zmu(z,s,w,mu,grid)*(y-z)+l_nm_d1_mu(z,s,w,mu,grid)))

  return(c(grad_z,c(grad_a),grad_mu))
}

ebnm_penalized_compound = function(x,s,grid,z_init = NULL,
                                   w_init=NULL,mu_init = 0,opt_method = 'L-BFGS-B'){
  n = length(x)
  K = length(grid)
  if(is.null(w_init)){
    w_init = rep(1/K,K)
  }
  if(length(s)==1){
    s = rep(s,n)
  }
  if(is.null(z_init)){
    z_init = x
  }
  if(is.null(mu_init)){
    mu_init = 0
  }
  out = optim(c(z_init,w_init,mu_init),
              fn=f_obj,
              gr=f_obj_grad,
              method=opt_method,
              y=y,grid=grid,s=s)
  z = out$par[1:n]
  a = out$par[(n+1):(n+K)]
  w = softmax(a)
  mu = out$par[n+K+1]
  posteriorMean = S(z,s,w,mu,grid)
  return(list(z=z,w=w,mu=mu,a=a,posteriorMean=posteriorMean,opt_res = out))
}

```

```{r}
fit = ebnm_penalized_compound(y,s,grid,opt_method = 'L-BFGS-B')
fit$w
fit$mu
fit$opt_res$value
```


```{r}
ploter(fit,y,lambda,main='compound penalty')
```

## inversion method

```{r}
#'objective function
#'@param theta (theta,w,mu)
#'@param grid prior sds
f_obj = function(params,y,s,grid,z_range){
  n = length(y)
  K = length(grid)
  w = softmax(params[(n+1):(n+K)])
  theta = params[1:n]
  mu = params[n+K+1]
  z = S_inv(theta,s,w,mu,grid,z_range)
  return(sum((y-theta)^2/2/s^2 - l_nm(z,s,w,mu,grid)-(z-theta)^2/2/s^2))
}


#'objective function
#'@param theta (theta,w,mu)
#'@param grid prior sds
f_obj_grad = function(params,y,s,grid,z_range){
  n = length(y)
  K = length(grid)
  a = params[(n+1):(n+K)]
  w = softmax(a)
  theta = params[1:n]
  mu = params[n+K+1]
  z = S_inv(theta,s,w,mu,grid,z_range)
  grad_theta = (z-y)/s^2
  grad_a = -colSums(l_nm_d1_a(z,s,a,mu,grid))
  grad_mu = -sum(l_nm_d1_mu(z,s,w,mu,grid))
  return(c(grad_theta,c(grad_a),grad_mu))
}


ebnm_penalized_inversion = function(x,s,grid,theta_init = NULL,
                                    w_init=NULL,mu_init=NULL,z_range=NULL,opt_method = 'L-BFGS-B'){
  n = length(x)
  K = length(grid)
  if(is.null(w_init)){
    w_init = rep(1/K,K)
  }
  if(length(s)==1){
    s = rep(s,n)
  }
  if(is.null(theta_init)){
    theta_init = rep(0,n)
  }
  if(is.null(z_range)){
    z_range = range(x) + c(-1,1)
  }
  if(is.null(mu_init)){
    mu_init = 0
  }
  params = c(theta_init,w_init,mu_init)
  out = optim(params,
                   fn=f_obj,
                   gr = f_obj_grad,
                 y=x,
                 s=s,
                 grid=grid,
                 z_range=z_range,
                 method = opt_method,
              control=list(maxit=1000,trace=1))
  
  return(list(posteriorMean = out$par[1:n],a = out$par[(n+1):(n+K)] ,w = softmax(out$par[(n+1):(n+K)]),mu=out$par[n+K+1],opt_res = out))
}
```

### init posterior mean at 0

```{r}
fit = ebnm_penalized_inversion(y,s,grid,opt_method = 'L-BFGS-B')
round(fit$w,3)
fit$mu
fit$opt_res$value
```


```{r}
ploter(fit,y,lambda,main='inversion method')
```

Take a look at the gradient.

```{r}
plot(f_obj_grad(c(fit$posteriorMean,fit$a,fit$mu),y,s,grid,c(-10,10)))
```

It seems that the gradient is not close to 0 enough...may need to change initialization or convergence criteria.

### init posterior mean at true ones

```{r}
fit = ebnm_penalized_inversion(y,s,grid,theta_init = fit.ash$result$PosteriorMean,opt_method = 'L-BFGS-B')
round(fit$w,3)
fit$mu
fit$opt_res$value
```


```{r}
ploter(fit,y,lambda,main='inversion method')
```

### init posterior mean at observation

```{r}
fit = ebnm_penalized_inversion(y,s,grid,theta_init = y,opt_method = 'L-BFGS-B')
round(fit$w,3)
fit$mu
fit$opt_res$value
```


```{r}
ploter(fit,y,lambda,main='inversion method')
```
